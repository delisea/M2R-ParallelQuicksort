# -*- coding: utf-8 -*-
#+STARTUP: overview indent inlineimages
#+TITLE:       Laboratory Notebook for a Multi-Threaded Version of Quicksort
#+AUTHOR:      Hugo Amodru-Favin, Antoine Delise
#+LANGUAGE:    fr
#+TAGS: IMPORTANT(i) TEST(t) DEPRECATED(d) noexport(n)

* Project Overview
This project aims at providing an efficient multi-threaded
implementation of the QuickSort algorithm on multi-core machines. This
document contains my attempts to evaluate the performance of an
implementation of such code.
* General Organization
** src/
This directory comprises the parallel implementation and a standard
Makefile to compile it.
** data/
This is where raw experimental data should go. Each directory entry
comprises a set of experiments and the directory name is based on the
machine name and on the date.
* Expérimentation
** Présentation de notre étude
Pour observer l'impact du matériel et du système d'exploitation sur les performances du quicksort. Nos deux machines ne tournent pas sur le même système d'exploitation, ont un processeur et une ram différentes.
Dans un premier temps, nous effectuerons la même expérience sur les deux machines différentes. On analysera les résultats obtenus indépendemment de la machine avant de les comparer pour conclure sur les performances machines.

Nous commencons d'abord par réaliser un make du programme de base du quicksort :
#+begin_src
./src/make
#+end_src

** Informations Machines
Présentation des 2 machines de tests utilisées : OS, CPU, Mémoire, Version du compilateur GCC.

*** Machine 1 (Hugo Amodru-Favin)

#+begin_src sh :results output :exports both 
uname -a
#+end_src

#+RESULTS:
: Linux Machine 4.6.0-kali1-amd64 #1 SMP Debian 4.6.4-1kali1 (2016-07-21) x86_64 GNU/Linux

#+begin_src
cat /proc/meminfo > Infos/Machine/meminfo.txt
#+end_src

#+begin_src
cat /proc/cpuinfo > Infos/Machine/cpuinfo.txt
#+end_src

#+begin_src sh :results output :exports both 
gcc --version
#+end_src

#+RESULTS:
: gcc (Debian 6.2.0-10) 6.2.0 20161027
: Copyright (C) 2016 Free Software Foundation, Inc.
: This is free software; see the source for copying conditions.  There is NO
: warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

Test simple du quicksort
#+begin_src sh :results output :exports both 
./src/parallelQuicksort
#+end_src

#+RESULTS:
: Sequential quicksort took: 0.224542 sec.
: Parallel quicksort took: 0.187741 sec.
: Built-in quicksort took: 0.246872 sec.

*** Machine 2 (Antoine Delise) 

#+begin_src sh :results output :exports both 
uname -a
#+end_src

#+RESULTS:
: Linux deliseport-GP60-2QE 4.4.0-53-generic #74-Ubuntu SMP Fri Dec 2 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

#+begin_src
cat /proc/meminfo > Infos/deliseport-FP60-2QE/meminfo.txt
#+end_src

#+begin_src
cat /proc/cpuinfo > Infos/deliseport-FP60-2QE/cpuinfo.txt
#+end_src

#+begin_src sh :results output :exports both 
gcc --version
#+end_src

#+RESULTS:
:gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
:Copyright (C) 2015 Free Software Foundation, Inc.
:This is free software; see the source for copying conditions.  There is NO
:warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


Test simple du quicksort
#+begin_src sh :results output :exports both 
./src/parallelQuicksort
#+end_src

#+RESULTS:
:Sequential quicksort took: 0.214918 sec.
:Parallel quicksort took: 0.419729 sec.
:Built-in quicksort took: 0.211146 sec.

** Expérimentations séparées

*** Notre expérience

On cherche a randomiser au maximum les tests
Les différents tests sont indiqués en paramètres lors de l'éxécution du fichier de test. C'est à dire qu'on peut réaliser un quantité infinie de tests. Chaque paramètre est un entier qui définit la tailles des tableaux utilisés lors de ce test.
L'éxécution "./script/test.sh 1000" réalisera un seul test avec des tableaux de tailles 1000, "./script/test.sh 1000 2000" réalisera un test avec des tableaux de taille 1000 et un second test avec des tableaux de taille 2000. 
Cela permet de créer deux tableaux à une dimension correspondant dont l'indice correspond d'un côté à la taille des tableaux de tests et de l'autre au nombre de tests à faire pour cette taille.
On choisit ensuite aléatoirement une taille de tableaux parmis celles qui doivent encore être testées jusqu'à ce qu'il n'y ait plus de test à effectué.

État final: Le tableau est rempli de $ma (nombre de test à faire par type, défini ici à 5)
Le script utilise le mini-programme "rand" qui génère un nombre aléatoire à partir d'un seed (en utilisant la fonction rand de la libc), afin de générer un meilleur aléatoire.
#+begin_src perl :results output raw :exports both :tangle scripts/mkdir -p $OUTPUT_DIRECTORY
TOUTPUT_FILE=$OUTPUT_DIRECTORY/measurements_`date +%R`
OUTPUT_FILE=$TOUTPUT_FILE.txt

touch $OUTPUT_FILE

let "randy = $(./scripts/rand 42)"
declare -A tes
declare -A tit
let "j = 0"
for i in $@; do
	 tit[${j}]=${i}
	 tes[${j}]=0
	 let "j = $j + 1"
done


let "ma = 5"
let "si = j"
let "len = j - 1"

let "k = $ma * $j"
while [ $k -ne 0 ]; do

# choix du test aléatoirement
let "randy = $(./scripts/rand $randy)"
let "val = $randy % $si"
let "i = 0"
while [ $val -ne 0 ]; do
	if [ ${tes[${i}]} -ne $ma ]
	then
		let "val = $val - 1"
	fi

	if [ ${i} -eq $len ]
   then
		let "i = 0"
	else
		let "i = i + 1"
	fi
done
	# on prends le premier valide
	while [ ${tes[${i}]} -eq $ma ]; do
		if [ ${i} -eq $len ]
		then
			let "i = 0"
		else
			let "i = i + 1"
		fi
	done

	echo "Size: ${tit[${i}]}" >> $OUTPUT_FILE;
        ./src/parallelQuicksort ${tit[${i}]} >> $OUTPUT_FILE;


	let "tes[${i}] = ${tes[${i}]} + 1"
	let "k = k - 1"
done
#+end_src

compute file data
#+begin_src perl :results output raw :exports both :tangle scripts/FILENAME=$TOUTPUT_FILE
perl scripts/csv_quicksort_extractor2.pl < "$FILENAME.txt" > "${FILENAME}_wide.csv"

sort -k1n,1n "${FILENAME}_wide.csv" > "${FILENAME}_wide_sorted.csv"
#+end_src


* Un meilleur indice de visualisation: la moyenne
Calcule des valeurs moyennes:
(On récupère les lignes commençant par "$VALTEST," (ex:1000,) avec sed puis on calcul les moyennes par lignes avec la commande awk).
#+begin_src perl :results output raw :exports both :tangle scripts/
echo Size, Seq, Par, Libc > "${FILENAME}_wide_mean.csv"

declare -A mean
for i in $@; do
	 sed -n -e "/^$i,/p" "${FILENAME}_wide.csv" > "data/t.csv"

	mean[0]=$(awk '{ total += $2 } END { print total/NR }' 'data/t.csv')
	mean[1]=$(awk '{ total += $3 } END { print total/NR }' 'data/t.csv')
	mean[2]=$(awk '{ total += $4 } END { print total/NR }' 'data/t.csv')
	echo $i, ${mean[0]}, ${mean[1]}, ${mean[2]} >> "${FILENAME}_wide_mean.csv"
done
#+end_src


*** A simple plot with gnuplot
Affichage des résultats sur des graphes:
#+begin_src sh :results output raw :exports both 
echo "
  set terminal png size 600,400 
  set output '${FILENAME}_wide.png'
  set datafile separator ','
  set key autotitle columnhead
	plot '${FILENAME}_wide_mean.csv' using 1:2 with linespoints, '' using 1:3 with linespoints, '' using 1:4 with linespoints, '${FILENAME}_wide_sorted.csv' using 1:2, '' using 1:3, '' using 1:4
" | gnuplot

echo [[file:${FILENAME}_wide.png]]
#+end_src

Test petites valeurs
#+RESULTS:
[[file:data/deliseport-GP60-2QE_2017-01-20/measurements_08:18_wide.png]]
Test moyennes valeurs
#+RESULTS:
[[file:data/deliseport-GP60-2QE_2017-01-20/measurements_08:30_wide.png]]
Test grande valeurs
#+RESULTS:
[[file:data/deliseport-GP60-2QE_2017-01-20/measurements_08:32_wide.png]]
Test très grandes valeurs
#+RESULTS:
[[file:data/deliseport-GP60-2QE_2017-01-20/measurements_08:20_wide.png]]


On peut voir que les performances sur des petites et moyennes valeurs sont beaucoup moins efficace pour la version parallèle. Mais à partir de 1500000 valeurs les performances très vite sont beaucoup plus éfficaces pour cette dernière jusque 60% du temps des autres algorythme à partir de 10^7.
